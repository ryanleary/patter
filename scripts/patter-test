#!/usr/bin/env python

import argparse
import toml
from patter import Evaluator, ModelFactory
from patter.data import AudioDataset


def get_parser():
    parser = argparse.ArgumentParser(description="Patter STT Test")
    parser.add_argument("model_path", help="Path to model to test")
    parser.add_argument("--test-config", required=True, help="Configuration file specifying testing parameters")
    parser.add_argument("--progress", action="store_true", help="If true, display progress bars, else use text output")
    parser.add_argument("--verbose", action="store_true", help="If true, display reference and hypothesized transcripts")

    return parser


def main():
    args = get_parser().parse_args()

    # load configuration
    with open(args.test_config, "r") as fh:
        testing_config = toml.load(fh)

    # initialize the model to test
    model = ModelFactory.load(args.model_path)

    # set up trainer and corpus
    evaluator = Evaluator.load(testing_config, tqdm=args.progress, verbose=args.verbose)

    # load the corpora
    test_corpus = AudioDataset.from_config(testing_config, model.input_cfg, model.labels, manifest="test")

    # kick off the test
    errors = evaluator.eval(model, test_corpus)
    print('Test Summary:')
    print('WER {wer:.3f} [ {errs} / {tokens}, {ins} ins, {dels} del, {sub} sub ]'
          .format(wer=errors.wer, errs=int(errors.wer*errors.tokens//100), tokens=errors.tokens,
                  ins=errors.word_errors["insert"], dels=errors.word_errors["delete"],
                  sub=errors.word_errors["replace"]))
    print('CER {cer:.3f} [ {errs} / {chars}, {ins} ins, {dels} del, {sub} sub ]'
          .format(cer=errors.cer, errs=int(errors.cer*errors.chars//100), chars=errors.chars,
                  ins=errors.char_errors["insert"], dels=errors.char_errors["delete"],
                  sub=errors.char_errors["replace"]))


if __name__ == '__main__':
    main()
